{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a61f0bb",
   "metadata": {},
   "source": [
    "Se define la clase SequencialDecisionTreeAlgorithm como solución al problema base propuesto, y SequencialModelAlgorithm a la clase modificada para contemplar el uso de nuevos modelos de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19ddf8",
   "metadata": {},
   "source": [
    "# SequentialDecisionTreeAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ac75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, preprocessing, model_selection\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn.utils as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class SequencialDecisionTreeAlgorithm:\n",
    "    # Se inicializan los hiper-parámetros como atributos dentro de la clase del problema\n",
    "    # @ filename Nombre del fichero a elegir como dataset. Se carga cuando se inicia el programa con el método self.start()\n",
    "    # @ ntree cantidad de árboles a secuencializar\n",
    "    # @ sample_size como proporción de ejemplos del conjunto de datos para entrenar cada árbol secuencial\n",
    "    # @ max_depth como profundidad máxima para el entrenamiento de los árboles de decisión\n",
    "    # @ lr como factor de aprendizaje\n",
    "    def __init__(self, ntree=300, sample_size=0.65, max_depth=10, lr=0.1, min_samples_leaf=1, max_features=None, min_weight_fraction_leaf=0.0):\n",
    "        self.ntree = ntree\n",
    "        self.sample_size = sample_size\n",
    "        self.max_depth = max_depth\n",
    "        self.lr = lr\n",
    "        self.pred = [0]\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "    \n",
    "    # Comienza el proceso de creación de árboles \n",
    "    # @ attributes_cols columnas de atributos\n",
    "    # @ objetive_col columna objetivo\n",
    "    # @ random_state variable opcional que sirve de semilla para el primer split de datos\n",
    "    # @ ftest_size variable opcional que sirve para elegir la proporción del primer split de datos\n",
    "    def start(self, attributes_cols, objetive_col, random_state=12345, ftest_size=0.33):\n",
    "        # Selección de columnas para atributos y objetivo\n",
    "        attributes = self.attributes_preprocess(attributes_cols)\n",
    "        objetive = self.objetive_preproccess(objetive_col)\n",
    "        \n",
    "        # Almacenamos mínimos y máximos de cada columna de los atributos para la futura clasificación\n",
    "        self.Xmin = attributes.min(axis = 0)\n",
    "        self.Xmax = attributes.max(axis = 0)\n",
    "        \n",
    "        # Hacemos nuestra primera predicción sobre los resultados medios de cada columna\n",
    "        cols_mean = attributes.mean(axis=0)\n",
    "        \n",
    "        (X_train, X_test, y_train, y_test) = model_selection.train_test_split(\n",
    "                attributes, objetive,\n",
    "                random_state=12345,\n",
    "                test_size=ftest_size,\n",
    "                stratify=objetive)\n",
    "\n",
    "\n",
    "        #Entrenamos nuestra primera iteración\n",
    "        Tree = tree.DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, max_features=self.max_features, min_weight_fraction_leaf=self.min_weight_fraction_leaf)\n",
    "        Tree = Tree.fit(X_train, y_train)\n",
    "        #Tree.plot_tree(clf)\n",
    "\n",
    "        self.pred = Tree.predict([cols_mean])\n",
    "\n",
    "        #print(Tree.score(X_test, y_test))\n",
    "        \n",
    "        trees = []\n",
    "        for i in range(self.ntree):\n",
    "            subtree, self.pred = self.meta_algorithm(X_test, y_test, self.pred)\n",
    "            trees.append(subtree)\n",
    "            \n",
    "        return trees, balanced_accuracy_score(y_test, self.classify_prediction(self.pred)) # realmente debería ser self.classify_prediction(self.pred)\n",
    "          \n",
    "    # Preprocesado de atributos. Codifica datos en formato de texto en numéricos  \n",
    "    # @ attributes_cols columnas de atributos\n",
    "    def attributes_preprocess(self, attributes_cols):\n",
    "        # Acumulamos las transformaciones necesarias en una matriz para realizarlas en la función ColumnTransformer\n",
    "        transforms = []\n",
    "        for i in attributes_cols: # Recorremos cada columna\n",
    "            # Primer valor de cada columna. Podríamos recorrer cada valor de la columna para asegurarnos de que sean\n",
    "            # numéricos o cadena de texto, pero en los Dataset de ejemplo nos vale con comprobar el primer valor.\n",
    "            fval = attributes_cols[i][0]\n",
    "\n",
    "            # Comprobamos que sea numérico, sino acumulamos una transformación sobre la columna\n",
    "            if isinstance(fval, (int, float, np.int64))==False:\n",
    "                transforms.append((\"encode-\"+i, preprocessing.OrdinalEncoder(), [i]))\n",
    "\n",
    "        # Devolvemos como respuesta un array de enteros aplicando las transformaciones acumuladas en transforms\n",
    "        # # remainder = 'passthrough' nos devolverá en la transformación también las columnas no afectadas\n",
    "        res = np.array(ColumnTransformer(transforms, remainder='passthrough').fit_transform(attributes_cols), dtype=float)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    # Preprocesado de la columna objetivo. Codifica datos en formato de texto en numéricos  \n",
    "    # @ objetive_col columnas objetivo\n",
    "    def objetive_preproccess(self, objetive_col):\n",
    "        # Primer valor de cada columna. Podríamos recorrer cada valor de la columna para asegurarnos de que sean\n",
    "        # numéricos o cadena de texto, pero en los Dataset de ejemplo nos vale con comprobar el primer valor.\n",
    "        fval = objetive_col[0]\n",
    "\n",
    "        if isinstance(fval, (int, float, np.int64))==False:\n",
    "            objetive_col = preprocessing.LabelEncoder().fit_transform(objetive_col)\n",
    "\n",
    "        return objetive_col\n",
    "    \n",
    "    # Meta-algoritmo\n",
    "    def meta_algorithm(self, X, y, prediction):        \n",
    "        # residuoi\n",
    "        i_res = y - prediction;\n",
    "\n",
    "        Xm, i_resm = self.sample_without_replacement(X, i_res, self.sample_size)\n",
    "\n",
    "        # Creamos un nuevo arbol que entrenamos con la muestra y su residuo\n",
    "        subtree = tree.DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, max_features=self.max_features, min_weight_fraction_leaf=self.min_weight_fraction_leaf)\n",
    "        subtree = subtree.fit(Xm, i_resm)\n",
    "\n",
    "        i_prediction = prediction + subtree.predict(X)*self.lr\n",
    "\n",
    "        # Añadimos el nuevo arbol a la variable respuesta\n",
    "        return subtree, i_prediction\n",
    "        \n",
    "    # Realiza un muestreo aleatorio de proporción sample_size del conjunto de datos y su residuo\n",
    "    def sample_without_replacement(self, test_set, res_set, sample_size):\n",
    "        # ordena aleatoriamente las dos matrices respetando que coincidan los índices\n",
    "        test_set, res_set = skl.shuffle(test_set, res_set)\n",
    "\n",
    "        # Limitamos la proporción de ejemplos según sample_size\n",
    "        limit = int(test_set.shape[0]*sample_size)\n",
    "\n",
    "        # Limitamos las matrices\n",
    "        sample = test_set[0:limit]\n",
    "        res = res_set[0:limit]\n",
    "\n",
    "        return sample, res\n",
    "    \n",
    "    def classify_prediction(self, pred):\n",
    "        Xmax = np.max(pred)\n",
    "        Xmin = np.min(pred)\n",
    "        for i in range(len(pred)):\n",
    "            pred[i] = np.around((pred[i] - Xmin)/(Xmax-Xmin))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1b604",
   "metadata": {},
   "source": [
    "Definiendo un objeto de esta clase, podremos resolver ejemplos con modelos de árboles de decisión. Las pruebas en los diferentes datasets se encuentran en los archivos tests_nombreDataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fe74e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9011075406774928\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('./datasets/adultDataset.csv', header = 0)\n",
    "attr_cols = dataset.loc[:, 'capital-gain':'native-country']\n",
    "obj_col = dataset['income']\n",
    "\n",
    "SeqTree = SequencialDecisionTreeAlgorithm() # hiperparámetros predeterminados\n",
    "trees, score = SeqTree.start(attributes_cols = attr_cols, objetive_col = obj_col)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a05e5b",
   "metadata": {},
   "source": [
    "# SequentialModelAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, preprocessing, model_selection\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn.utils as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class SequencialDecisionTreeAlgorithm:\n",
    "    # Se inicializan los hiper-parámetros como atributos dentro de la clase del problema\n",
    "    # @ filename Nombre del fichero a elegir como dataset. Se carga cuando se inicia el programa con el método self.start()\n",
    "    # @ ntree cantidad de árboles a secuencializar\n",
    "    # @ sample_size como proporción de ejemplos del conjunto de datos para entrenar cada árbol secuencial\n",
    "    # @ max_depth como profundidad máxima para el entrenamiento de los árboles de decisión\n",
    "    # @ lr como factor de aprendizaje\n",
    "    def __init__(self, ntree=300, sample_size=0.65, max_depth=10, lr=0.1, min_samples_leaf=1, max_features=None, min_weight_fraction_leaf=0.0):\n",
    "        self.ntree = ntree\n",
    "        self.sample_size = sample_size\n",
    "        self.max_depth = max_depth\n",
    "        self.lr = lr\n",
    "        self.pred = [0]\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "    \n",
    "    # Comienza el proceso de creación de árboles \n",
    "    # @ attributes_cols columnas de atributos\n",
    "    # @ objetive_col columna objetivo\n",
    "    # @ random_state variable opcional que sirve de semilla para el primer split de datos\n",
    "    # @ ftest_size variable opcional que sirve para elegir la proporción del primer split de datos\n",
    "    def start(self, attributes_cols, objetive_col, random_state=12345, ftest_size=0.33):\n",
    "        # Selección de columnas para atributos y objetivo\n",
    "        attributes = self.attributes_preprocess(attributes_cols)\n",
    "        objetive = self.objetive_preproccess(objetive_col)\n",
    "        \n",
    "        # Almacenamos mínimos y máximos de cada columna de los atributos para la futura clasificación\n",
    "        self.Xmin = attributes.min(axis = 0)\n",
    "        self.Xmax = attributes.max(axis = 0)\n",
    "        \n",
    "        # Hacemos nuestra primera predicción sobre los resultados medios de cada columna\n",
    "        cols_mean = attributes.mean(axis=0)\n",
    "        \n",
    "        # Realizamos la primera muestra\n",
    "        (X_train, X_test, y_train, y_test) = model_selection.train_test_split(\n",
    "                attributes, objetive,\n",
    "                random_state=12345,\n",
    "                test_size=ftest_size,\n",
    "                stratify=objetive)\n",
    "\n",
    "\n",
    "        #Entrenamos nuestra primera iteración\n",
    "        Tree = tree.DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, max_features=self.max_features, min_weight_fraction_leaf=self.min_weight_fraction_leaf)\n",
    "        Tree = Tree.fit(X_train, y_train)\n",
    "        #Tree.plot_tree(clf)\n",
    "\n",
    "        self.pred = Tree.predict([cols_mean])\n",
    "\n",
    "        #print(Tree.score(X_test, y_test))\n",
    "        \n",
    "        trees = []\n",
    "        for i in range(self.ntree):\n",
    "            subtree, self.pred = self.meta_algorithm(X_test, y_test, self.pred)\n",
    "            trees.append(subtree)\n",
    "            \n",
    "        return trees, balanced_accuracy_score(y_test, self.classify_prediction(self.pred)) # realmente debería ser self.classify_prediction(self.pred)\n",
    "          \n",
    "    # Preprocesado de atributos. Codifica datos en formato de texto en numéricos  \n",
    "    # @ attributes_cols columnas de atributos\n",
    "    def attributes_preprocess(self, attributes_cols):\n",
    "        # Acumulamos las transformaciones necesarias en una matriz para realizarlas en la función ColumnTransformer\n",
    "        transforms = []\n",
    "        for i in attributes_cols: # Recorremos cada columna\n",
    "            # Primer valor de cada columna. Podríamos recorrer cada valor de la columna para asegurarnos de que sean\n",
    "            # numéricos o cadena de texto, pero en los Dataset de ejemplo nos vale con comprobar el primer valor.\n",
    "            fval = attributes_cols[i][0]\n",
    "\n",
    "            # Comprobamos que sea numérico, sino acumulamos una transformación sobre la columna\n",
    "            if isinstance(fval, (int, float, np.int64))==False:\n",
    "                transforms.append((\"encode-\"+i, preprocessing.OrdinalEncoder(), [i]))\n",
    "\n",
    "        # Devolvemos como respuesta un array de enteros aplicando las transformaciones acumuladas en transforms\n",
    "        # # remainder = 'passthrough' nos devolverá en la transformación también las columnas no afectadas\n",
    "        res = np.array(ColumnTransformer(transforms, remainder='passthrough').fit_transform(attributes_cols), dtype=float)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    # Preprocesado de la columna objetivo. Codifica datos en formato de texto en numéricos  \n",
    "    # @ objetive_col columnas objetivo\n",
    "    def objetive_preproccess(self, objetive_col):\n",
    "        # Primer valor de cada columna. Podríamos recorrer cada valor de la columna para asegurarnos de que sean\n",
    "        # numéricos o cadena de texto, pero en los Dataset de ejemplo nos vale con comprobar el primer valor.\n",
    "        fval = objetive_col[0]\n",
    "\n",
    "        if isinstance(fval, (int, float, np.int64))==False:\n",
    "            objetive_col = preprocessing.LabelEncoder().fit_transform(objetive_col)\n",
    "\n",
    "        return objetive_col\n",
    "    \n",
    "    # Meta-algoritmo\n",
    "    def meta_algorithm(self, X, y, prediction):        \n",
    "        # residuoi\n",
    "        i_res = y - prediction;\n",
    "\n",
    "        Xm, i_resm = self.sample_without_replacement(X, i_res, self.sample_size)\n",
    "\n",
    "        # Creamos un nuevo arbol que entrenamos con la muestra y su residuo\n",
    "        subtree = tree.DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, max_features=self.max_features, min_weight_fraction_leaf=self.min_weight_fraction_leaf)\n",
    "        subtree = subtree.fit(Xm, i_resm)\n",
    "\n",
    "        i_prediction = prediction + subtree.predict(X)*self.lr\n",
    "\n",
    "        # Añadimos el nuevo arbol a la variable respuesta\n",
    "        return subtree, i_prediction\n",
    "        \n",
    "    # Realiza un muestreo aleatorio de proporción sample_size del conjunto de datos y su residuo\n",
    "    def sample_without_replacement(self, test_set, res_set, sample_size):\n",
    "        # ordena aleatoriamente las dos matrices respetando que coincidan los índices\n",
    "        test_set, res_set = skl.shuffle(test_set, res_set)\n",
    "\n",
    "        # Limitamos la proporción de ejemplos según sample_size\n",
    "        limit = int(test_set.shape[0]*sample_size)\n",
    "\n",
    "        # Limitamos las matrices\n",
    "        sample = test_set[0:limit]\n",
    "        res = res_set[0:limit]\n",
    "\n",
    "        return sample, res\n",
    "    \n",
    "    def classify_prediction(self, pred):\n",
    "        Xmax = np.max(pred)\n",
    "        Xmin = np.min(pred)\n",
    "        for i in range(len(pred)):\n",
    "            pred[i] = np.around((pred[i] - Xmin)/(Xmax-Xmin))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31fc9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573687447259742\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo\n",
    "\n",
    "dataset = pd.read_csv('./datasets/adultDataset.csv', header = 0)\n",
    "attr_cols = dataset.loc[:, 'capital-gain':'native-country']\n",
    "obj_col = dataset['income']\n",
    "\n",
    "# Usando vecinos más cercanos knn\n",
    "SeqTree = SequencialModelAlgorithm(nmodels = 20, method = \"knn\")\n",
    "trees, score = SeqTree.start(attributes_cols = attr_cols, objetive_col = obj_col)\n",
    "    \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec665e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
